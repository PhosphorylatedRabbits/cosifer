{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip3 install networkx"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import site\n","import sys\n","\n","sys.path.append(site.USER_SITE)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import logging\n","\n","from multiprocessing import Pool, cpu_count\n","from pathlib import Path\n","\n","import matplotlib.pyplot as plt\n","import networkx as nx\n","import pandas as pd\n","from cosifer.combiners import COMBINERS, RECOMMENDED_COMBINER\n","from cosifer.inferencers import INFERENCERS, RECOMMENDED_INFERENCERS\n","from cosifer.pipelines.pipeline_cli import run as cli_run, run_combiner, get_interaction_tables\n","from cosifer.pipelines.pipeline_gui import run as gui_run\n","\n","logging.getLogger('matplotlib').setLevel(logging.WARNING)\n","\n","FILEPATH = os.path.abspath('data_matrix.csv')"]},{"cell_type":"markdown","metadata":{},"source":["# Application of cosifer pipeline with dummy data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# to download the the dummy data file\n","# from [Box](https://ibm.box.com/s/x6fvci11k6x7napo1wgt74mgs5jvfy9x):\n","# !mkdir -p /data/demo\n","# !curl -L https://ibm.box.com/shared/static/x6fvci11k6x7napo1wgt74mgs5jvfy9x.csv -o /data/demo/data_matrix.csv\n","# !ls -l /data/demo\n","# !head -n 3 /data/demo/data_matrix.csv\n","# FILEPATH = '/data/demo/data_matrix.csv'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.read_csv(FILEPATH)\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Run a pipeline\n","We could use either the function executed via the command line interface or in the\n","[web service](http://www.ibm.biz/cosifer-aas)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(gui_run.__doc__)\n","print(cli_run.__doc__)"]},{"cell_type":"markdown","metadata":{},"source":["The **difference** is mainly that the gui version happens in memory, that is it\n","doesn't read the input file but accepts a pd.DataFrame and does not save the\n","individual networks, but only the final combined one to disk.\n","(Also the gui version does not offer to repeat the run for multiple feature\n","subsets via `gmt_filepath`)\n","\n","The gui version is therefore a bit easier to inspect and get an idea of what is\n","happending, but later we will use functions used in the cli pipeline to run\n","things in parallel.\n","\n","They have in **common** that they sequentially\n","- run different network inference methods in series\n","- run a combiner"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["gui_run(\n","    df, '/data/demo/gui_default_inference.csv.gz',\n","    # methods=INFERENCERS.keys()  # run all methods\n",")"]},{"cell_type":"markdown","metadata":{},"source":["This ran some default inference methods and the default combiner"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["RECOMMENDED_INFERENCERS, list(INFERENCERS.keys())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["RECOMMENDED_COMBINER, list(COMBINERS.keys())"]},{"cell_type":"markdown","metadata":{},"source":["... and resulted in a compressed csv."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!gzip -cd /data/demo/gui_default_inference.csv.gz | head\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["inference_results = pd.read_csv(\n","    '/data/demo/gui_default_inference.csv.gz', header=0, index_col=0,\n","    compression='gzip'\n",").sort_values('intensity', ascending=False)\n","len(inference_results)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# draw edges with top 50 intensity\n","G = nx.from_pandas_edgelist(inference_results[:50], 'e1', 'e2', 'intensity')\n","nx.draw_spring(G, with_labels=True)\n",""]},{"cell_type":"markdown","metadata":{},"source":["## Not running a pipeline\n","This allows some more finegrained control, for example only using the consensus\n","methods on your own interaction networks.\n","\n","\n","Here we show how to run different inference methods in parallel.\n","Saving the networks of individual inference methods allows running multiple\n","combiners without recomputing them."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["inference_directory = '/data/demo/parallel/inference/'\n","combiner_directory = '/data/demo/parallel/combiner/'\n","data = df\n","\n","\n","def run_single_method(name, inferencer):\n","    output_filepath = '{}/{}.csv.gz'.format(inference_directory, name)\n","    if not os.path.exists(output_filepath):\n","        inferencer.filepath = output_filepath\n","        inferencer.load()  # will log again that file is not there yet\n","        inferencer.infer_network(data)\n","        # NOTE: allow retraining on new data\n","        inferencer.trained = False\n","    else:\n","        print(\n","            'inference already run and stored in {}'.\n","            format(output_filepath)\n","        )\n","\n","\n","selected_methods = INFERENCERS"]},{"cell_type":"markdown","metadata":{},"source":["Note that the values in this `INFERENCERS` dict are (stateful) instances with\n","default parameters.\n","\n","Here you could create you own dict with different parameters, or\n","even instances of your own implementations inheriting from\n","`cosifer.network_inferencer.NetworkInferencer`"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == \"__main__\":\n","    # parallelize inference running methods at the same time\n","    print(f'we are running {cpu_count()} processes in parellel')\n","    with Pool() as pool:\n","        pool.starmap(run_single_method, selected_methods.items())\n","        # in series, this compares to\n","        # list(map(run_single_method, selected_methods.keys(), selected_methods.values()))\n","        # list(map(run_single_method, *zip(*selected_methods.items())))\n","\n","    # find and read interaction tables\n","    tables = get_interaction_tables(inference_directory)\n","    # run combination\n","    run_combiner(RECOMMENDED_COMBINER, tables, combiner_directory)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!ls $inference_directory\n","!ls $combiner_directory"]},{"cell_type":"markdown","metadata":{},"source":["Done!"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":2}}